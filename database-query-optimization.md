# ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á Database Query

## ‡∏™‡∏≤‡∏£‡∏ö‡∏±‡∏ç (Table of Contents)

### üî∞ **‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô (Beginner)**
1. [‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏° Query Performance](#1-‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°-query-performance)
2. [‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏ä‡πâ SELECT ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏£‡∏≠‡∏ö‡∏Ñ‡∏≠‡∏ö](#2-‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏ä‡πâ-select-‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏£‡∏≠‡∏ö‡∏Ñ‡∏≠‡∏ö)
3. [‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ WHERE Clause ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û](#3-‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ-where-clause-‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û)

### üìö **‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Å‡∏•‡∏≤‡∏á (Intermediate)**
4. [‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ Index ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û](#4-‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ-index-‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û)
5. [‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ JOIN ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°](#5-‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ-join-‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°)
6. [‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ LIMIT ‡πÅ‡∏•‡∏∞ OFFSET ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°](#6-‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ-limit-‡πÅ‡∏•‡∏∞-offset-‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°)
7. [‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ Aggregate Functions ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ä‡∏≤‡∏ç‡∏â‡∏•‡∏≤‡∏î](#7-‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ-aggregate-functions-‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ä‡∏≤‡∏ç‡∏â‡∏•‡∏≤‡∏î)
8. [‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ Query Caching](#8-‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ-query-caching)

### üéì **‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏™‡∏π‡∏á (Advanced)**
9. [Common Table Expressions (WITH Clause)](#9-common-table-expressions-with-clause)
10. [Window Functions ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•](#10-window-functions-‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•)
11. [‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Temporary Tables ‡πÅ‡∏•‡∏∞ Memory](#11-‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£-temporary-tables-‡πÅ‡∏•‡∏∞-memory)
12. [Bulk Operations ‡πÅ‡∏•‡∏∞ Batch Processing](#12-bulk-operations-‡πÅ‡∏•‡∏∞-batch-processing)

### üîß **‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç (Expert)**
13. [‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á Database Schema](#13-‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á-database-schema)
14. [‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ Query Hints ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°](#14-‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ-query-hints-‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°)
15. [Best Practices ‡∏™‡∏£‡∏∏‡∏õ](#15-best-practices-‡∏™‡∏£‡∏∏‡∏õ)
16. [‡∏™‡∏£‡∏∏‡∏õ](#‡∏™‡∏£‡∏∏‡∏õ)

---

## 1. ‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏° Query Performance

### ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ EXPLAIN:
```sql
-- ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Execution Plan
EXPLAIN SELECT * FROM orders 
WHERE customer_id = 123 
  AND order_date BETWEEN '2024-01-01' AND '2024-01-31';

-- ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏ö‡∏ö‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î
EXPLAIN FORMAT=JSON 
SELECT * FROM orders 
WHERE customer_id = 123 
  AND order_date BETWEEN '2024-01-01' AND '2024-01-31';
```

### ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ Slow Query Log:
```sql
-- ‡πÄ‡∏õ‡∏¥‡∏î Slow Query Log
SET GLOBAL slow_query_log = 'ON';
SET GLOBAL long_query_time = 1; -- Log queries ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 1 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ

-- ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Slow Queries
SELECT * FROM mysql.slow_log 
WHERE start_time > DATE_SUB(NOW(), INTERVAL 1 DAY)
ORDER BY query_time DESC;
```

### ‡∏Å‡∏≤‡∏£‡∏ß‡∏±‡∏î‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û:
```go
package main

import (
    "database/sql"
    "encoding/json"
    "fmt"
    "log"
    "runtime"
    "time"
    
    _ "github.com/go-sql-driver/mysql"
)

// Constants
const (
    BytesToMB           = 1024 * 1024
    SecondsDecimalPlace = 4
    MBDecimalPlace      = 2
    PerformanceDecimalPlace = 2
)

// Error constants
const (
    ErrQueryExecution = "query execution failed"
    ErrGetColumns     = "failed to get columns"
    ErrScanFailed     = "scan failed"
    ErrDatabaseConn   = "failed to connect to database"
)

// Interfaces for better testability
type DatabaseExecutor interface {
    Query(query string, args ...interface{}) (*sql.Rows, error)
}

type PerformanceLogger interface {
    LogPerformance(result *QueryResult)
}

// Structs
type QueryParams struct {
    Query string
    Args  []interface{}
}

type QueryResult struct {
    Data          []map[string]interface{} `json:"data"`
    ExecutionTime float64                  `json:"execution_time"`
    MemoryUsed    int64                    `json:"memory_used"`
    RowsReturned  int                      `json:"rows_returned"`
}

type PerformanceMeasurer struct {
    DB     DatabaseExecutor
    Logger PerformanceLogger
}

type ConsoleLogger struct{}

func (cl *ConsoleLogger) LogPerformance(result *QueryResult) {
    fmt.Printf("Execution time: %.*f seconds\n", SecondsDecimalPlace, result.ExecutionTime)
    fmt.Printf("Memory used: %.*f MB\n", MBDecimalPlace, float64(result.MemoryUsed)/BytesToMB)
    fmt.Printf("Rows returned: %d\n", result.RowsReturned)
    
    if result.ExecutionTime > 0 {
        performanceScore := float64(result.RowsReturned) / result.ExecutionTime
        fmt.Printf("Performance score: %.*f rows/sec\n", PerformanceDecimalPlace, performanceScore)
    }
}

func NewPerformanceMeasurer(db DatabaseExecutor) *PerformanceMeasurer {
    return &PerformanceMeasurer{
        DB:     db,
        Logger: &ConsoleLogger{},
    }
}

func (pm *PerformanceMeasurer) MeasureQueryPerformance(params QueryParams) (*QueryResult, error) {
    memBefore := pm.captureMemoryStats()
    startTime := time.Now()
    
    rows, err := pm.DB.Query(params.Query, params.Args...)
    if err != nil {
        return nil, fmt.Errorf("%s: %w", ErrQueryExecution, err)
    }
    defer rows.Close()
    
    results, err := pm.processRows(rows)
    if err != nil {
        return nil, err
    }
    
    result := pm.buildQueryResult(results, startTime, memBefore)
    pm.Logger.LogPerformance(result)
    
    return result, nil
}

func (pm *PerformanceMeasurer) captureMemoryStats() runtime.MemStats {
    var memStats runtime.MemStats
    runtime.GC()
    runtime.ReadMemStats(&memStats)
    return memStats
}

func (pm *PerformanceMeasurer) processRows(rows *sql.Rows) ([]map[string]interface{}, error) {
    columns, err := rows.Columns()
    if err != nil {
        return nil, fmt.Errorf("%s: %w", ErrGetColumns, err)
    }
    
    var results []map[string]interface{}
    for rows.Next() {
        row, err := pm.scanRow(rows, columns)
        if err != nil {
            return nil, err
        }
        results = append(results, row)
    }
    
    return results, nil
}

func (pm *PerformanceMeasurer) scanRow(rows *sql.Rows, columns []string) (map[string]interface{}, error) {
    values := make([]interface{}, len(columns))
    valuePtrs := make([]interface{}, len(columns))
    for i := range values {
        valuePtrs[i] = &values[i]
    }
    
    if err := rows.Scan(valuePtrs...); err != nil {
        return nil, fmt.Errorf("%s: %w", ErrScanFailed, err)
    }
    
    row := make(map[string]interface{})
    for i, col := range columns {
        row[col] = values[i]
    }
    
    return row, nil
}

func (pm *PerformanceMeasurer) buildQueryResult(results []map[string]interface{}, 
    startTime time.Time, memBefore runtime.MemStats) *QueryResult {
    
    executionTime := time.Since(startTime).Seconds()
    
    var memAfter runtime.MemStats
    runtime.ReadMemStats(&memAfter)
    memoryUsed := int64(memAfter.TotalAlloc - memBefore.TotalAlloc)
    
    return &QueryResult{
        Data:          results,
        ExecutionTime: executionTime,
        MemoryUsed:    memoryUsed,
        RowsReturned:  len(results),
    }
}

// ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
func main() {
    db, err := sql.Open("mysql", "user:password@tcp(localhost:3306)/database")
    if err != nil {
        log.Fatalf("%s: %v", ErrDatabaseConn, err)
    }
    defer db.Close()
    
    measurer := NewPerformanceMeasurer(db)
    
    params := QueryParams{
        Query: "SELECT customer_id, SUM(total_amount) FROM orders WHERE order_date >= ? GROUP BY customer_id",
        Args:  []interface{}{"2024-01-01"},
    }
    
    result, err := measurer.MeasureQueryPerformance(params)
    if err != nil {
        log.Fatal(err)
    }
    
    jsonResult, _ := json.MarshalIndent(result, "", "  ")
    fmt.Printf("Result: %s\n", jsonResult)
}
```

### ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Performance Monitoring:
```sql
-- MySQL: Performance Schema
SELECT 
    DIGEST_TEXT,
    COUNT_STAR,
    AVG_TIMER_WAIT/1000000000 as avg_seconds,
    SUM_TIMER_WAIT/1000000000 as total_seconds
FROM performance_schema.events_statements_summary_by_digest
ORDER BY SUM_TIMER_WAIT DESC
LIMIT 10;

-- ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Index Usage
SELECT 
    object_schema,
    object_name,
    index_name,
    count_read,
    count_write,
    count_fetch,
    count_insert,
    count_update,
    count_delete
FROM performance_schema.table_io_waits_summary_by_index_usage
WHERE object_schema = 'your_database'
ORDER BY count_read DESC;
```

## 2. ‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏ä‡πâ SELECT ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏£‡∏≠‡∏ö‡∏Ñ‡∏≠‡∏ö

### ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ SELECT *
```sql
-- ‡πÑ‡∏°‡πà‡∏î‡∏µ: ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
SELECT * FROM orders 
WHERE customer_id = 123;
```

### ‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç:
```sql
-- ‡∏î‡∏µ: ‡∏£‡∏∞‡∏ö‡∏∏‡πÄ‡∏â‡∏û‡∏≤‡∏∞ columns ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
SELECT order_id, order_date, total_amount 
FROM orders 
WHERE customer_id = 123;
```

### ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏à‡∏£‡∏¥‡∏á - ‡∏£‡∏∞‡∏ö‡∏ö CRM:
```sql
-- ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: API ‡∏ó‡∏µ‡πà‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡πÉ‡∏ä‡πâ SELECT *
SELECT * FROM customers WHERE status = 'active';

-- ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: ‡∏î‡∏∂‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
SELECT customer_id, first_name, last_name, email, phone 
FROM customers 
WHERE status = 'active';
```

## 3. ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ WHERE Clause ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û

### ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ LIKE ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ú‡∏¥‡∏î‡∏ß‡∏¥‡∏ò‡∏µ:
```sql
-- ‡∏ä‡πâ‡∏≤: LIKE ‡∏ó‡∏µ‡πà‡∏Ç‡∏∂‡πâ‡∏ô‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢ %
SELECT * FROM products WHERE product_name LIKE '%phone%';

-- ‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏ß‡πà‡∏≤: LIKE ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏Ç‡∏∂‡πâ‡∏ô‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢ %
SELECT * FROM products WHERE product_name LIKE 'iPhone%';
```

### ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏à‡∏£‡∏¥‡∏á - ‡∏£‡∏∞‡∏ö‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤:
```sql
-- ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: ‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏ö‡∏ö Full-text ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û
SELECT * FROM articles 
WHERE title LIKE '%web development%' 
   OR content LIKE '%web development%';

-- ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: ‡πÉ‡∏ä‡πâ Full-text Search Index
-- ‡∏™‡∏£‡πâ‡∏≤‡∏á Full-text Index
CREATE FULLTEXT INDEX idx_articles_search ON articles(title, content);

-- ‡πÉ‡∏ä‡πâ Full-text Search
SELECT * FROM articles 
WHERE MATCH(title, content) AGAINST('web development' IN NATURAL LANGUAGE MODE);
```

## 4. ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ Index ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û

### ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢:
```sql
-- Query ‡∏ó‡∏µ‡πà‡∏ä‡πâ‡∏≤: ‡πÑ‡∏°‡πà‡∏°‡∏µ Index
SELECT * FROM users WHERE email = 'john@example.com';
```

### ‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç:
```sql
-- ‡∏™‡∏£‡πâ‡∏≤‡∏á Index ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö email column
CREATE INDEX idx_users_email ON users(email);

-- ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ Unique Index ‡∏´‡∏≤‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏≠‡∏Å‡∏•‡∏±‡∏Å‡∏©‡∏ì‡πå
CREATE UNIQUE INDEX idx_users_email_unique ON users(email);
```

### ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á - ‡∏£‡∏∞‡∏ö‡∏ö E-commerce:
```sql
-- ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: ‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏ï‡∏≤‡∏° category_id ‡∏ä‡πâ‡∏≤
SELECT product_id, product_name, price 
FROM products 
WHERE category_id = 5 
ORDER BY created_at DESC 
LIMIT 10;

-- ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: ‡∏™‡∏£‡πâ‡∏≤‡∏á Composite Index
CREATE INDEX idx_products_category_created ON products(category_id, created_at DESC);
```

### ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏´‡∏£‡πà‡∏Ñ‡∏ß‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á Index:
```sql
-- ‚úÖ ‡∏Ñ‡∏ß‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á Index ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö:
-- 1. Columns ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô WHERE clause ‡∏ö‡πà‡∏≠‡∏¢‡πÜ
CREATE INDEX idx_orders_status ON orders(status);

-- 2. Foreign Key columns
CREATE INDEX idx_order_items_order_id ON order_items(order_id);

-- 3. Columns ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô ORDER BY
CREATE INDEX idx_products_created_at ON products(created_at);

-- 4. Composite Index ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö queries ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏´‡∏•‡∏≤‡∏¢ columns
CREATE INDEX idx_orders_customer_date ON orders(customer_id, order_date);
```

### ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏£‡∏∞‡∏ß‡∏±‡∏á‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á Index:
```sql
-- ‚ùå ‡πÑ‡∏°‡πà‡∏Ñ‡∏ß‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á Index ‡∏°‡∏≤‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ
-- ‡∏Å‡∏≤‡∏£ INSERT/UPDATE/DELETE ‡∏à‡∏∞‡∏ä‡πâ‡∏≤‡∏•‡∏á

-- ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Index ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÉ‡∏ä‡πâ
SELECT 
    s.schemaname,
    s.tablename,
    s.indexname,
    s.idx_tup_read,
    s.idx_tup_fetch
FROM pg_stat_user_indexes s
WHERE s.idx_tup_read = 0 AND s.idx_tup_fetch = 0;

-- ‡∏•‡∏ö Index ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÉ‡∏ä‡πâ
DROP INDEX IF EXISTS unused_index_name;
```

## 5. ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ JOIN ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°

### ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ Subquery ‡πÅ‡∏ó‡∏ô JOIN
```sql
-- ‡∏ä‡πâ‡∏≤: ‡πÉ‡∏ä‡πâ Subquery
SELECT p.product_name, p.price
FROM products p
WHERE p.category_id IN (
    SELECT c.category_id 
    FROM categories c 
    WHERE c.status = 'active'
);
```

### ‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç:
```sql
-- ‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏ß‡πà‡∏≤: ‡πÉ‡∏ä‡πâ INNER JOIN
SELECT p.product_name, p.price
FROM products p
INNER JOIN categories c ON p.category_id = c.category_id
WHERE c.status = 'active';
```

### ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏à‡∏£‡∏¥‡∏á - ‡∏£‡∏∞‡∏ö‡∏ö‡∏Å‡∏≤‡∏£‡∏Ç‡∏≤‡∏¢:
```sql
-- ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡πÉ‡∏ä‡πâ Multiple Subqueries
SELECT 
    s.sales_id,
    (SELECT customer_name FROM customers WHERE customer_id = s.customer_id) as customer_name,
    (SELECT product_name FROM products WHERE product_id = s.product_id) as product_name,
    s.quantity * s.unit_price as total
FROM sales s
WHERE s.sale_date BETWEEN '2024-01-01' AND '2024-01-31';

-- ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: ‡πÉ‡∏ä‡πâ JOIN
SELECT 
    s.sales_id,
    c.customer_name,
    p.product_name,
    s.quantity * s.unit_price as total
FROM sales s
INNER JOIN customers c ON s.customer_id = c.customer_id
INNER JOIN products p ON s.product_id = p.product_id
WHERE s.sale_date BETWEEN '2024-01-01' AND '2024-01-31';
```

### ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏≠‡∏á JOIN ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô:
```sql
-- INNER JOIN: ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô both tables
SELECT c.customer_name, o.total_amount
FROM customers c
INNER JOIN orders o ON c.customer_id = o.customer_id;

-- LEFT JOIN: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏à‡∏≤‡∏Å left table
SELECT c.customer_name, COUNT(o.order_id) as order_count
FROM customers c
LEFT JOIN orders o ON c.customer_id = o.customer_id
GROUP BY c.customer_id, c.customer_name;

-- EXISTS vs IN: ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö subqueries
-- ‡πÉ‡∏ä‡πâ EXISTS ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å subquery
SELECT c.customer_name
FROM customers c
WHERE EXISTS (
    SELECT 1 FROM orders o 
    WHERE o.customer_id = c.customer_id 
    AND o.order_date >= '2024-01-01'
);
```

## 6. ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ LIMIT ‡πÅ‡∏•‡∏∞ OFFSET ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°

### ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ OFFSET ‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà
```sql
-- ‡∏ä‡πâ‡∏≤‡∏°‡∏≤‡∏Å: OFFSET ‡∏ó‡∏µ‡πà‡πÉ‡∏´‡∏ç‡πà
SELECT * FROM products 
ORDER BY created_at 
LIMIT 10 OFFSET 50000;
```

### ‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç - Cursor-based Pagination:
```sql
-- ‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏ß‡πà‡∏≤: ‡πÉ‡∏ä‡πâ Cursor-based pagination
SELECT * FROM products 
WHERE created_at < '2024-01-15 10:30:00'
ORDER BY created_at DESC 
LIMIT 10;
```

### ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏à‡∏£‡∏¥‡∏á - API Pagination:
```sql
-- ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: ‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á‡∏´‡∏ô‡πâ‡∏≤‡∏Ç‡∏≠‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÇ‡∏û‡∏™‡∏ï‡πå
SELECT post_id, title, created_at 
FROM posts 
ORDER BY created_at DESC 
LIMIT 10 OFFSET :page_offset;

-- ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: ‡πÉ‡∏ä‡πâ ID-based pagination
SELECT post_id, title, created_at 
FROM posts 
WHERE post_id < :last_post_id 
ORDER BY post_id DESC 
LIMIT 10;
```

## 7. ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ Aggregate Functions ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ä‡∏≤‡∏ç‡∏â‡∏•‡∏≤‡∏î

### ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: ‡∏Å‡∏≤‡∏£‡∏ô‡∏±‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
```sql
-- ‡∏ä‡πâ‡∏≤: COUNT(*) ‡∏ö‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÉ‡∏´‡∏ç‡πà
SELECT COUNT(*) FROM users;
```

### ‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç:
```sql
-- ‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏ß‡πà‡∏≤: ‡πÉ‡∏ä‡πâ Approximate count ‡∏´‡∏£‡∏∑‡∏≠ Cache
-- ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö MySQL
SELECT table_rows 
FROM information_schema.tables 
WHERE table_name = 'users' 
  AND table_schema = DATABASE();
```

### ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏à‡∏£‡∏¥‡∏á - Dashboard Analytics:
```sql
-- ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á Dashboard ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ô‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏≤‡∏¢‡∏ï‡∏≤‡∏£‡∏≤‡∏á
SELECT 
    (SELECT COUNT(*) FROM users) as total_users,
    (SELECT COUNT(*) FROM orders) as total_orders,
    (SELECT COUNT(*) FROM products) as total_products;

-- ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: ‡πÉ‡∏ä‡πâ Summary Table ‡∏´‡∏£‡∏∑‡∏≠ Materialized View
-- ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á summary
CREATE TABLE dashboard_stats (
    stat_name VARCHAR(50),
    stat_value INT,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Update ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡πâ‡∏ß‡∏¢ Scheduled Job
INSERT INTO dashboard_stats (stat_name, stat_value)
VALUES 
    ('total_users', (SELECT COUNT(*) FROM users)),
    ('total_orders', (SELECT COUNT(*) FROM orders)),
    ('total_products', (SELECT COUNT(*) FROM products))
ON DUPLICATE KEY UPDATE 
    stat_value = VALUES(stat_value),
    updated_at = CURRENT_TIMESTAMP;
```

## 8. ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ Query Caching

### ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ Redis Cache:
```go
package main

import (
    "context"
    "database/sql"
    "encoding/json"
    "fmt"
    "log"
    "time"
    
    "github.com/go-redis/redis/v8"
    _ "github.com/go-sql-driver/mysql"
)

// Constants
const (
    DefaultCacheExpiration = 5 * time.Minute
    DefaultRedisDB         = 0
    CacheKeyPattern       = "popular_products:%d"
)

// Error constants
const (
    ErrDatabaseConnection = "failed to connect to database"
    ErrRedisConnection    = "failed to connect to redis"
    ErrDatabaseQuery      = "database query failed"
    ErrScanProducts       = "failed to scan product"
    ErrCacheUnmarshal     = "failed to unmarshal cached data"
    ErrCacheMarshal       = "failed to marshal data for cache"
)

// Messages
const (
    MsgDataFromCache    = "Data retrieved from cache"
    MsgQueryingDatabase = "Querying database..."
    MsgDataCached       = "Data cached for %v"
    MsgCacheTestSeparator = "\n--- Calling again to test cache ---"
)

// Interfaces for better testability
type DatabaseQuerier interface {
    Query(query string, args ...interface{}) (*sql.Rows, error)
    Close() error
}

type CacheManager interface {
    Get(ctx context.Context, key string) (string, error)
    SetEX(ctx context.Context, key string, value interface{}, expiration time.Duration) error
    Close() error
}

type ProductRepository interface {
    GetPopularProducts(limit int) ([]Product, error)
}

// Structs
type Product struct {
    ProductID   int     `json:"product_id"`
    ProductName string  `json:"product_name"`
    Price       float64 `json:"price"`
    OrderCount  int     `json:"order_count"`
}

type CacheConfig struct {
    RedisAddr    string
    RedisPassword string
    RedisDB      int
    Expiration   time.Duration
}

type CacheService struct {
    DB     DatabaseQuerier
    Cache  CacheManager
    Ctx    context.Context
    Config CacheConfig
}

func NewCacheConfig(redisAddr string) CacheConfig {
    return CacheConfig{
        RedisAddr:    redisAddr,
        RedisPassword: "",
        RedisDB:      DefaultRedisDB,
        Expiration:   DefaultCacheExpiration,
    }
}

func NewCacheService(dbConnection string, config CacheConfig) (*CacheService, error) {
    db, err := sql.Open("mysql", dbConnection)
    if err != nil {
        return nil, fmt.Errorf("%s: %w", ErrDatabaseConnection, err)
    }
    
    rdb := redis.NewClient(&redis.Options{
        Addr:     config.RedisAddr,
        Password: config.RedisPassword,
        DB:       config.RedisDB,
    })
    
    return &CacheService{
        DB:     db,
        Cache:  rdb,
        Ctx:    context.Background(),
        Config: config,
    }, nil
}

func (cs *CacheService) GetPopularProducts(limit int) ([]Product, error) {
    cacheKey := fmt.Sprintf(CacheKeyPattern, limit)
    
    products, err := cs.getProductsFromCache(cacheKey)
    if err == nil {
        fmt.Println(MsgDataFromCache)
        return products, nil
    }
    
    products, err = cs.getProductsFromDatabase(limit)
    if err != nil {
        return nil, err
    }
    
    cs.cacheProducts(cacheKey, products)
    
    return products, nil
}

func (cs *CacheService) getProductsFromCache(cacheKey string) ([]Product, error) {
    cachedResult, err := cs.Cache.Get(cs.Ctx, cacheKey)
    if err != nil {
        return nil, err
    }
    
    var products []Product
    if err := json.Unmarshal([]byte(cachedResult), &products); err != nil {
        return nil, fmt.Errorf("%s: %w", ErrCacheUnmarshal, err)
    }
    
    return products, nil
}

func (cs *CacheService) getProductsFromDatabase(limit int) ([]Product, error) {
    fmt.Println(MsgQueryingDatabase)
    
    query := `
        SELECT p.product_id, p.product_name, p.price, 
               COUNT(oi.product_id) as order_count
        FROM products p
        LEFT JOIN order_items oi ON p.product_id = oi.product_id
        GROUP BY p.product_id, p.product_name, p.price
        ORDER BY order_count DESC
        LIMIT ?
    `
    
    rows, err := cs.DB.Query(query, limit)
    if err != nil {
        return nil, fmt.Errorf("%s: %w", ErrDatabaseQuery, err)
    }
    defer rows.Close()
    
    return cs.scanProducts(rows)
}

func (cs *CacheService) scanProducts(rows *sql.Rows) ([]Product, error) {
    var products []Product
    for rows.Next() {
        var p Product
        if err := rows.Scan(&p.ProductID, &p.ProductName, &p.Price, &p.OrderCount); err != nil {
            return nil, fmt.Errorf("%s: %w", ErrScanProducts, err)
        }
        products = append(products, p)
    }
    return products, nil
}

func (cs *CacheService) cacheProducts(cacheKey string, products []Product) {
    jsonData, err := json.Marshal(products)
    if err != nil {
        log.Printf("%s: %v", ErrCacheMarshal, err)
        return
    }
    
    if err := cs.Cache.SetEX(cs.Ctx, cacheKey, string(jsonData), cs.Config.Expiration); err != nil {
        log.Printf("Failed to cache data: %v", err)
        return
    }
    
    fmt.Printf(MsgDataCached+"\n", cs.Config.Expiration)
}

func (cs *CacheService) Close() error {
    if err := cs.DB.Close(); err != nil {
        return err
    }
    return cs.Cache.Close()
}

// ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
func main() {
    config := NewCacheConfig("localhost:6379")
    
    cacheService, err := NewCacheService(
        "user:password@tcp(localhost:3306)/database",
        config,
    )
    if err != nil {
        log.Fatal("Error creating cache service:", err)
    }
    defer cacheService.Close()
    
    // ‡∏î‡∏∂‡∏á‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏¢‡∏≠‡∏î‡∏ô‡∏¥‡∏¢‡∏° 10 ‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡πÅ‡∏£‡∏Å
    products, err := cacheService.GetPopularProducts(10)
    if err != nil {
        log.Fatal("Error:", err)
    }
    
    // ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
    jsonResult, _ := json.MarshalIndent(products, "", "  ")
    fmt.Printf("Popular Products:\n%s\n", jsonResult)
    
    // ‡∏•‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏î‡∏™‡∏≠‡∏ö cache
    fmt.Println(MsgCacheTestSeparator)
    products2, _ := cacheService.GetPopularProducts(10)
    jsonResult2, _ := json.MarshalIndent(products2, "", "  ")
    fmt.Printf("Popular Products (from cache):\n%s\n", jsonResult2)
}
```

## 9. Common Table Expressions (WITH Clause)

### ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ WITH ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÉ‡∏î:

#### 1. ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà Subqueries ‡∏ó‡∏µ‡πà‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô:
```sql
-- ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: Nested Subqueries ‡∏ó‡∏µ‡πà‡∏≠‡πà‡∏≤‡∏ô‡∏¢‡∏≤‡∏Å
SELECT 
    customer_id,
    total_orders,
    avg_order_value
FROM (
    SELECT 
        customer_id,
        COUNT(*) as total_orders,
        AVG(order_amount) as avg_order_value
    FROM (
        SELECT 
            o.customer_id,
            SUM(oi.quantity * oi.unit_price) as order_amount
        FROM orders o
        JOIN order_items oi ON o.order_id = oi.order_id
        WHERE o.order_date >= '2024-01-01'
        GROUP BY o.order_id, o.customer_id
    ) order_totals
    GROUP BY customer_id
    HAVING COUNT(*) >= 5
) customer_stats;

-- ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: ‡πÉ‡∏ä‡πâ WITH ‡πÉ‡∏´‡πâ‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢‡∏Ç‡∏∂‡πâ‡∏ô
WITH order_totals AS (
    SELECT 
        o.customer_id,
        o.order_id,
        SUM(oi.quantity * oi.unit_price) as order_amount
    FROM orders o
    JOIN order_items oi ON o.order_id = oi.order_id
    WHERE o.order_date >= '2024-01-01'
    GROUP BY o.order_id, o.customer_id
),
customer_stats AS (
    SELECT 
        customer_id,
        COUNT(*) as total_orders,
        AVG(order_amount) as avg_order_value
    FROM order_totals
    GROUP BY customer_id
    HAVING COUNT(*) >= 5
)
SELECT customer_id, total_orders, avg_order_value
FROM customer_stats;
```

#### 2. ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏ã‡πâ‡∏≥‡πÉ‡∏ô‡∏´‡∏•‡∏≤‡∏¢‡∏ó‡∏µ‡πà:
```sql
-- ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏£‡∏≤‡∏¢‡πÄ‡∏î‡∏∑‡∏≠‡∏ô
WITH monthly_sales AS (
    SELECT 
        DATE_FORMAT(order_date, '%Y-%m') as month,
        SUM(total_amount) as monthly_total,
        COUNT(*) as order_count
    FROM orders
    WHERE order_date >= DATE_SUB(CURDATE(), INTERVAL 12 MONTH)
    GROUP BY DATE_FORMAT(order_date, '%Y-%m')
)
SELECT 
    current_month.month,
    current_month.monthly_total,
    current_month.order_count,
    LAG(monthly_total) OVER (ORDER BY month) as previous_month_total,
    ROUND(
        (current_month.monthly_total - LAG(monthly_total) OVER (ORDER BY month)) 
        / LAG(monthly_total) OVER (ORDER BY month) * 100, 2
    ) as growth_percentage
FROM monthly_sales current_month
ORDER BY month;
```

#### 3. Recursive CTE ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Hierarchical Data:
```sql
-- ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: Organization Chart
WITH RECURSIVE employee_hierarchy AS (
    -- Base case: Top-level managers
    SELECT 
        employee_id,
        employee_name,
        manager_id,
        0 as level,
        CAST(employee_name AS CHAR(1000)) as path
    FROM employees
    WHERE manager_id IS NULL
    
    UNION ALL
    
    -- Recursive case: Subordinates
    SELECT 
        e.employee_id,
        e.employee_name,
        e.manager_id,
        eh.level + 1,
        CONCAT(eh.path, ' -> ', e.employee_name)
    FROM employees e
    JOIN employee_hierarchy eh ON e.manager_id = eh.employee_id
    WHERE eh.level < 10  -- Prevent infinite recursion
)
SELECT employee_id, employee_name, level, path
FROM employee_hierarchy
ORDER BY level, employee_name;
```

## 10. Window Functions ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•

### ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ Window Functions ‡πÅ‡∏ó‡∏ô Self-Join:
```sql
-- ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: Self-join ‡∏ó‡∏µ‡πà‡∏ä‡πâ‡∏≤
SELECT 
    o1.order_id,
    o1.order_date,
    o1.total_amount,
    (SELECT COUNT(*) FROM orders o2 WHERE o2.order_date <= o1.order_date) as running_count
FROM orders o1
ORDER BY o1.order_date;

-- ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: ‡πÉ‡∏ä‡πâ Window Function
SELECT 
    order_id,
    order_date,
    total_amount,
    ROW_NUMBER() OVER (ORDER BY order_date) as running_count,
    SUM(total_amount) OVER (ORDER BY order_date ROWS UNBOUNDED PRECEDING) as running_total
FROM orders
ORDER BY order_date;
```

### ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏à‡∏£‡∏¥‡∏á - Sales Analytics:
```sql
-- ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô
SELECT 
    employee_id,
    employee_name,
    monthly_sales,
    -- Ranking
    ROW_NUMBER() OVER (ORDER BY monthly_sales DESC) as sales_rank,
    DENSE_RANK() OVER (ORDER BY monthly_sales DESC) as dense_rank,
    
    -- Percentile
    PERCENT_RANK() OVER (ORDER BY monthly_sales) as percentile_rank,
    
    -- Moving averages
    AVG(monthly_sales) OVER (
        ORDER BY employee_id 
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    ) as moving_avg_3months,
    
    -- Comparison with previous period
    LAG(monthly_sales, 1) OVER (PARTITION BY employee_id ORDER BY month) as prev_month_sales,
    monthly_sales - LAG(monthly_sales, 1) OVER (PARTITION BY employee_id ORDER BY month) as month_over_month_change
FROM (
    SELECT 
        e.employee_id,
        e.employee_name,
        DATE_FORMAT(s.sale_date, '%Y-%m') as month,
        SUM(s.amount) as monthly_sales
    FROM employees e
    JOIN sales s ON e.employee_id = s.employee_id
    GROUP BY e.employee_id, e.employee_name, DATE_FORMAT(s.sale_date, '%Y-%m')
) monthly_data;
```

## 11. ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Temporary Tables ‡πÅ‡∏•‡∏∞ Memory

### ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö Temporary Tables vs CTEs vs Table Variables:

#### Temporary Tables (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà):
```sql
-- ‡πÉ‡∏ä‡πâ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ Index ‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏≤‡∏Å
CREATE TEMPORARY TABLE temp_sales_summary (
    customer_id INT,
    total_sales DECIMAL(15,2),
    order_count INT,
    INDEX idx_customer (customer_id),
    INDEX idx_sales (total_sales)
);

INSERT INTO temp_sales_summary
SELECT 
    customer_id,
    SUM(total_amount) as total_sales,
    COUNT(*) as order_count
FROM orders
WHERE order_date >= DATE_SUB(CURDATE(), INTERVAL 1 YEAR)
GROUP BY customer_id;

-- ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏ï‡πà‡∏≠
SELECT 
    t.customer_id,
    c.customer_name,
    t.total_sales,
    t.order_count,
    CASE 
        WHEN t.total_sales > 100000 THEN 'VIP'
        WHEN t.total_sales > 50000 THEN 'Premium'
        ELSE 'Standard'
    END as customer_tier
FROM temp_sales_summary t
JOIN customers c ON t.customer_id = c.customer_id
WHERE t.order_count >= 10;

DROP TEMPORARY TABLE temp_sales_summary;
```

#### Memory Engine Tables (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡∏™‡∏π‡∏á):
```sql
-- ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Cache ‡∏´‡∏£‡∏∑‡∏≠ Session data
CREATE TABLE session_cart (
    session_id VARCHAR(64),
    product_id INT,
    quantity INT,
    added_at TIMESTAMP,
    INDEX idx_session (session_id)
) ENGINE=MEMORY;
```

## 12. Bulk Operations ‡πÅ‡∏•‡∏∞ Batch Processing

### ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ BULK INSERT ‡πÅ‡∏ó‡∏ô Multiple INSERT:
```sql
-- ‡πÑ‡∏°‡πà‡∏î‡∏µ: Multiple INSERT statements
INSERT INTO products (name, price, category_id) VALUES ('Product 1', 99.99, 1);
INSERT INTO products (name, price, category_id) VALUES ('Product 2', 149.99, 1);
INSERT INTO products (name, price, category_id) VALUES ('Product 3', 199.99, 2);
-- ... repeat 1000 times

-- ‡∏î‡∏µ: Single BULK INSERT
INSERT INTO products (name, price, category_id) VALUES 
('Product 1', 99.99, 1),
('Product 2', 149.99, 1),
('Product 3', 199.99, 2),
-- ... all 1000 records in one statement
('Product 1000', 299.99, 3);
```

### ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ MERGE ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö UPSERT Operations:
```sql
-- ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï inventory ‡∏à‡∏≤‡∏Å external system
MERGE inventory AS target
USING (
    SELECT product_id, new_quantity, last_updated
    FROM temp_inventory_updates
) AS source ON target.product_id = source.product_id
WHEN MATCHED AND source.last_updated > target.last_updated THEN
    UPDATE SET 
        quantity = source.new_quantity,
        last_updated = source.last_updated
WHEN NOT MATCHED THEN
    INSERT (product_id, quantity, last_updated)
    VALUES (source.product_id, source.new_quantity, source.last_updated);
```

### Batch Processing ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà:
```go
package main

import (
    "database/sql"
    "fmt"
    "log"
    "strings"
    "time"
    
    _ "github.com/go-sql-driver/mysql"
)

// Constants
const (
    DefaultBatchSize          = 1000
    BatchProcessingDelay      = 100 * time.Millisecond
    RowProcessingDelay        = 1 * time.Millisecond
    
    // Stats keys
    StatsKeyProcessed = "processed"
    StatsKeyPending   = "pending"
)

// Error constants
const (
    ErrDatabaseConnection    = "failed to connect to database"
    ErrQueryBatch           = "failed to query batch"
    ErrScanRow              = "failed to scan row"
    ErrBeginTransaction     = "failed to begin transaction"
    ErrUpdateStatus         = "failed to update processed status"
    ErrCommitTransaction    = "failed to commit transaction"
    ErrValidation          = "data_column is empty for ID %d"
)

// Messages
const (
    MsgProcessingComplete = "Batch processing completed. Total rows processed: %d"
    MsgProgressUpdate     = "Processed batch: %d rows, Total processed: %d"
    MsgProcessingError    = "Error processing row %d: %v"
    MsgBeforeProcessing   = "Before processing - Processed: %d, Pending: %d"
    MsgAfterProcessing    = "After processing - Processed: %d, Pending: %d"
    MsgTotalTime         = "Total processing time: %v"
    MsgBatchProcessingFailed = "Batch processing failed:"
)

// Interfaces for better testability
type DatabaseExecutor interface {
    Query(query string, args ...interface{}) (*sql.Rows, error)
    QueryRow(query string, args ...interface{}) *sql.Row
    Begin() (*sql.Tx, error)
    Close() error
}

type TransactionManager interface {
    Exec(query string, args ...interface{}) (sql.Result, error)
    Commit() error
    Rollback() error
}

type RowProcessor interface {
    ProcessRow(row DataRow) error
}

// Structs
type DataRow struct {
    ID         int    `db:"id"`
    DataColumn string `db:"data_column"`
}

type ProcessingStats map[string]int

type BatchConfig struct {
    BatchSize int
    Delay     time.Duration
}

type BatchProcessor struct {
    DB        DatabaseExecutor
    Config    BatchConfig
    Processor RowProcessor
}

type DefaultRowProcessor struct{}

func (drp *DefaultRowProcessor) ProcessRow(row DataRow) error {
    // Simulate processing time
    time.Sleep(RowProcessingDelay)
    
    // ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£ validate ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    if row.DataColumn == "" {
        return fmt.Errorf(ErrValidation, row.ID)
    }
    
    // ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    // processedData := strings.ToUpper(row.DataColumn)
    // ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
    
    return nil
}

func NewBatchConfig(batchSize int) BatchConfig {
    return BatchConfig{
        BatchSize: batchSize,
        Delay:     BatchProcessingDelay,
    }
}

func NewBatchProcessor(dbConnection string, config BatchConfig) (*BatchProcessor, error) {
    db, err := sql.Open("mysql", dbConnection)
    if err != nil {
        return nil, fmt.Errorf("%s: %w", ErrDatabaseConnection, err)
    }
    
    return &BatchProcessor{
        DB:        db,
        Config:    config,
        Processor: &DefaultRowProcessor{},
    }, nil
}

func (bp *BatchProcessor) ProcessLargeDatasetInBatches() error {
    offset := 0
    totalProcessed := 0
    
    for {
        batch, err := bp.fetchBatch(offset)
        if err != nil {
            return err
        }
        
        if len(batch) == 0 {
            break
        }
        
        processedCount, err := bp.processBatch(batch)
        if err != nil {
            return err
        }
        
        totalProcessed += processedCount
        offset += bp.Config.BatchSize
        
        bp.logProgress(processedCount, totalProcessed)
        time.Sleep(bp.Config.Delay)
    }
    
    fmt.Printf(MsgProcessingComplete+"\n", totalProcessed)
    return nil
}

func (bp *BatchProcessor) fetchBatch(offset int) ([]DataRow, error) {
    query := `
        SELECT id, data_column 
        FROM large_table 
        WHERE processed = 0
        ORDER BY id 
        LIMIT ? OFFSET ?
    `
    
    rows, err := bp.DB.Query(query, bp.Config.BatchSize, offset)
    if err != nil {
        return nil, fmt.Errorf("%s: %w", ErrQueryBatch, err)
    }
    defer rows.Close()
    
    return bp.scanRows(rows)
}

func (bp *BatchProcessor) scanRows(rows *sql.Rows) ([]DataRow, error) {
    var batch []DataRow
    for rows.Next() {
        var row DataRow
        if err := rows.Scan(&row.ID, &row.DataColumn); err != nil {
            return nil, fmt.Errorf("%s: %w", ErrScanRow, err)
        }
        batch = append(batch, row)
    }
    return batch, nil
}

func (bp *BatchProcessor) processBatch(batch []DataRow) (int, error) {
    tx, err := bp.DB.Begin()
    if err != nil {
        return 0, fmt.Errorf("%s: %w", ErrBeginTransaction, err)
    }
    defer tx.Rollback()
    
    processedIDs := bp.processRows(batch)
    
    if len(processedIDs) > 0 {
        if err := bp.updateProcessedStatus(tx, processedIDs); err != nil {
            return 0, err
        }
    }
    
    if err := tx.Commit(); err != nil {
        return 0, fmt.Errorf("%s: %w", ErrCommitTransaction, err)
    }
    
    return len(processedIDs), nil
}

func (bp *BatchProcessor) processRows(batch []DataRow) []int {
    var processedIDs []int
    for _, row := range batch {
        if err := bp.Processor.ProcessRow(row); err != nil {
            log.Printf(MsgProcessingError, row.ID, err)
            continue
        }
        processedIDs = append(processedIDs, row.ID)
    }
    return processedIDs
}

func (bp *BatchProcessor) updateProcessedStatus(tx TransactionManager, ids []int) error {
    placeholders := make([]string, len(ids))
    args := make([]interface{}, len(ids))
    for i, id := range ids {
        placeholders[i] = "?"
        args[i] = id
    }
    
    updateQuery := fmt.Sprintf(`
        UPDATE large_table 
        SET processed = 1, 
            processed_at = NOW()
        WHERE id IN (%s)
    `, strings.Join(placeholders, ","))
    
    _, err := tx.Exec(updateQuery, args...)
    if err != nil {
        return fmt.Errorf("%s: %w", ErrUpdateStatus, err)
    }
    
    return nil
}

func (bp *BatchProcessor) logProgress(batchCount, totalCount int) {
    fmt.Printf(MsgProgressUpdate+"\n", batchCount, totalCount)
}

func (bp *BatchProcessor) GetProcessingStats() (ProcessingStats, error) {
    stats := make(ProcessingStats)
    
    processed, err := bp.getProcessedCount()
    if err != nil {
        return nil, err
    }
    stats[StatsKeyProcessed] = processed
    
    pending, err := bp.getPendingCount()
    if err != nil {
        return nil, err
    }
    stats[StatsKeyPending] = pending
    
    return stats, nil
}

func (bp *BatchProcessor) getProcessedCount() (int, error) {
    var processed int
    err := bp.DB.QueryRow("SELECT COUNT(*) FROM large_table WHERE processed = 1").Scan(&processed)
    return processed, err
}

func (bp *BatchProcessor) getPendingCount() (int, error) {
    var pending int
    err := bp.DB.QueryRow("SELECT COUNT(*) FROM large_table WHERE processed = 0").Scan(&pending)
    return pending, err
}

func (bp *BatchProcessor) Close() error {
    return bp.DB.Close()
}

// ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
func main() {
    config := NewBatchConfig(DefaultBatchSize)
    
    processor, err := NewBatchProcessor(
        "user:password@tcp(localhost:3306)/database",
        config,
    )
    if err != nil {
        log.Fatal("Error creating batch processor:", err)
    }
    defer processor.Close()
    
    // ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
    stats, _ := processor.GetProcessingStats()
    fmt.Printf(MsgBeforeProcessing+"\n", 
        stats[StatsKeyProcessed], stats[StatsKeyPending])
    
    // ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏ö‡∏ö batch
    startTime := time.Now()
    if err := processor.ProcessLargeDatasetInBatches(); err != nil {
        log.Fatal(MsgBatchProcessingFailed, err)
    }
    processingTime := time.Since(startTime)
    
    // ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏´‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
    stats, _ = processor.GetProcessingStats()
    fmt.Printf(MsgAfterProcessing+"\n", 
        stats[StatsKeyProcessed], stats[StatsKeyPending])
    fmt.Printf(MsgTotalTime+"\n", processingTime)
}
```

## 13. ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á Database Schema

### ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ Partitioning:
```sql
-- ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: ‡πÅ‡∏ö‡πà‡∏á Partition ‡∏ï‡∏≤‡∏°‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Log Table
CREATE TABLE user_logs (
    log_id INT AUTO_INCREMENT,
    user_id INT,
    action VARCHAR(100),
    log_date DATE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    PRIMARY KEY (log_id, log_date)
)
PARTITION BY RANGE (YEAR(log_date)) (
    PARTITION p2023 VALUES LESS THAN (2024),
    PARTITION p2024 VALUES LESS THAN (2025),
    PARTITION p2025 VALUES LESS THAN (2026),
    PARTITION p_future VALUES LESS THAN MAXVALUE
);
```

### ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ Denormalization ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°:
```sql
-- ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: ‡∏Å‡∏≤‡∏£ JOIN ‡∏´‡∏•‡∏≤‡∏¢‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô
SELECT 
    o.order_id,
    c.customer_name,
    c.customer_email,
    p.product_name,
    oi.quantity,
    oi.unit_price
FROM orders o
JOIN customers c ON o.customer_id = c.customer_id
JOIN order_items oi ON o.order_id = oi.order_id
JOIN products p ON oi.product_id = p.product_id;

-- ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: ‡∏™‡∏£‡πâ‡∏≤‡∏á Denormalized table ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô
CREATE TABLE order_reports (
    order_id INT,
    customer_name VARCHAR(100),
    customer_email VARCHAR(100),
    product_name VARCHAR(200),
    quantity INT,
    unit_price DECIMAL(10,2),
    order_date DATE,
    INDEX idx_order_date (order_date),
    INDEX idx_customer_email (customer_email)
);
```

### ‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Storage Engine ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°:
```sql
-- InnoDB: ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö OLTP (Online Transaction Processing)
CREATE TABLE orders (
    order_id INT AUTO_INCREMENT PRIMARY KEY,
    customer_id INT,
    order_date DATE,
    total_amount DECIMAL(10,2),
    FOREIGN KEY (customer_id) REFERENCES customers(customer_id)
) ENGINE=InnoDB;

-- MyISAM: ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Read-heavy workloads (deprecated in newer versions)
-- ‡πÑ‡∏°‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡πÅ‡∏•‡πâ‡∏ß

-- Memory: ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Temporary data
CREATE TABLE session_data (
    session_id VARCHAR(64),
    data TEXT,
    expires_at TIMESTAMP
) ENGINE=MEMORY;

-- Archive: ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Historical data
CREATE TABLE audit_logs (
    log_id INT AUTO_INCREMENT PRIMARY KEY,
    table_name VARCHAR(64),
    action VARCHAR(20),
    old_values JSON,
    new_values JSON,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
) ENGINE=ARCHIVE;
```

## 14. ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ Query Hints ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°

### MySQL Query Hints:
```sql
-- ‡πÉ‡∏ä‡πâ Specific Index
SELECT /*+ USE_INDEX(orders, idx_customer_date) */ 
    order_id, total_amount 
FROM orders 
WHERE customer_id = 123 AND order_date >= '2024-01-01';

-- Force Join Order
SELECT /*+ STRAIGHT_JOIN */
    c.customer_name, o.order_date, o.total_amount
FROM customers c
JOIN orders o ON c.customer_id = o.customer_id
WHERE c.status = 'active';

-- Use Temporary Table ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Subquery
SELECT /*+ USE_TMP_TABLE */ 
    customer_id, AVG(total_amount)
FROM orders
WHERE order_date >= '2024-01-01'
GROUP BY customer_id;
```

### SQL Server Query Hints:
```sql
-- Use Specific Join Algorithm
SELECT c.customer_name, o.total_amount
FROM customers c
INNER MERGE JOIN orders o ON c.customer_id = o.customer_id
WHERE c.status = 'active';

-- Parallel Processing
SELECT customer_id, SUM(total_amount)
FROM orders
WHERE order_date >= '2024-01-01'
GROUP BY customer_id
OPTION (MAXDOP 4);

-- Use Plan Guide
SELECT /*+ RECOMPILE */ 
    product_id, SUM(quantity)
FROM order_items
WHERE order_date BETWEEN @start_date AND @end_date
GROUP BY product_id;
```

### ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏´‡∏£‡πà‡∏Ñ‡∏ß‡∏£‡πÉ‡∏ä‡πâ Hints:
```sql
-- ‚úÖ ‡πÉ‡∏ä‡πâ‡πÄ‡∏°‡∏∑‡πà‡∏≠: Query Optimizer ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å plan ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°
-- ‚ùå ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ‡πÄ‡∏°‡∏∑‡πà‡∏≠: ‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏ô‡πÄ‡∏´‡∏ï‡∏∏

-- ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°: Force index ‡πÄ‡∏°‡∏∑‡πà‡∏≠ optimizer ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ú‡∏¥‡∏î
SELECT /*+ USE_INDEX(orders, idx_status_date) */
    order_id, customer_id, total_amount
FROM orders
WHERE status IN ('pending', 'processing')
  AND order_date >= CURDATE() - INTERVAL 7 DAY;
```

## 15. Best Practices ‡∏™‡∏£‡∏∏‡∏õ

### ‚úÖ ‡∏Ñ‡∏ß‡∏£‡∏ó‡∏≥:
- **‡∏ß‡∏±‡∏î‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏Å‡πà‡∏≠‡∏ô‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á** - ‡πÉ‡∏ä‡πâ EXPLAIN ‡πÅ‡∏•‡∏∞ monitoring tools
- **‡∏™‡∏£‡πâ‡∏≤‡∏á Index ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°** - ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö columns ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô WHERE, JOIN, ORDER BY
- **‡πÉ‡∏ä‡πâ LIMIT ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î** - ‡∏•‡∏î‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
- **‡∏£‡∏∞‡∏ö‡∏∏ columns ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ô SELECT** - ‡πÅ‡∏ó‡∏ô SELECT *
- **‡πÉ‡∏ä‡πâ Prepared Statements** - ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô SQL Injection ‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û
- **‡πÉ‡∏ä‡πâ Connection Pooling** - ‡∏•‡∏î‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Database
- **Cache ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡πÉ‡∏ä‡πâ‡∏ö‡πà‡∏≠‡∏¢‡πÜ** - ‡πÉ‡∏ä‡πâ Redis ‡∏´‡∏£‡∏∑‡∏≠ Memcached
- **‡πÉ‡∏ä‡πâ JOIN ‡πÅ‡∏ó‡∏ô Subqueries** - ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡πÑ‡∏î‡πâ
- **‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á** - ‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå performance ‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡∏à‡∏≥

### ‚ùå ‡πÑ‡∏°‡πà‡∏Ñ‡∏ß‡∏£‡∏ó‡∏≥:
- **‡πÉ‡∏ä‡πâ SELECT * ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô** - ‡∏™‡∏¥‡πâ‡∏ô‡πÄ‡∏õ‡∏•‡∏∑‡∏≠‡∏á bandwidth ‡πÅ‡∏•‡∏∞ memory
- **‡πÉ‡∏ä‡πâ LIKE ‡∏ó‡∏µ‡πà‡∏Ç‡∏∂‡πâ‡∏ô‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢ %** - ‡∏ó‡∏≥‡πÉ‡∏´‡πâ index ‡πÑ‡∏°‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
- **‡πÉ‡∏ä‡πâ Functions ‡πÉ‡∏ô WHERE clause ‡∏Å‡∏±‡∏ö indexed columns** - ‡∏ó‡∏≥‡∏•‡∏≤‡∏¢ index optimization
- **‡∏™‡∏£‡πâ‡∏≤‡∏á Index ‡∏°‡∏≤‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô** - ‡∏ó‡∏≥‡πÉ‡∏´‡πâ INSERT/UPDATE/DELETE ‡∏ä‡πâ‡∏≤
- **‡πÉ‡∏ä‡πâ OFFSET ‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà** - ‡πÉ‡∏ä‡πâ cursor-based pagination ‡πÅ‡∏ó‡∏ô
- **‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Å‡πà‡∏≠‡∏ô‡∏ß‡∏±‡∏î** - "Premature optimization is the root of all evil"
- **‡πÉ‡∏ä‡πâ Hints ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ß‡∏±‡∏á** - ‡∏≠‡∏≤‡∏à‡∏ó‡∏≥‡πÉ‡∏´‡πâ performance ‡πÅ‡∏¢‡πà‡∏•‡∏á‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÑ‡∏õ

### üîÑ ‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:
1. **üìä Measure** - ‡∏ß‡∏±‡∏î‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
2. **üîç Analyze** - ‡∏´‡∏≤‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏±‡∏ç‡∏´‡∏≤ (bottlenecks)
3. **‚öôÔ∏è Optimize** - ‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°
4. **üß™ Test** - ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö
5. **üìù Document** - ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡πÅ‡∏•‡∏∞‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
6. **üîÅ Repeat** - ‡∏ó‡∏≥‡∏ã‡πâ‡∏≥‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡∏à‡∏≥

### üèÖ Performance Metrics ‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°:
- **Query Response Time** - ‡πÄ‡∏ß‡∏•‡∏≤‡∏ï‡∏≠‡∏ö‡∏™‡∏ô‡∏≠‡∏á‡∏Ç‡∏≠‡∏á Query
- **Throughput** - ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô queries ‡∏ï‡πà‡∏≠‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ
- **Connection Pool Usage** - ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô connection pool
- **Index Hit Ratio** - ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ index
- **Memory Usage** - ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ RAM ‡πÅ‡∏•‡∏∞ Buffer Pool
- **Disk I/O** - ‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô/‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å storage

### üöÄ ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Experts:
- **Read Replicas** - ‡πÅ‡∏¢‡∏Å Read ‡πÅ‡∏•‡∏∞ Write operations
- **Database Sharding** - ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πâ‡∏≤‡∏° multiple databases
- **Query Result Caching** - Cache ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏ô‡∏≤‡∏ô
- **Database Monitoring** - ‡πÉ‡∏ä‡πâ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡πÄ‡∏ä‡πà‡∏ô Datadog, New Relic ‡∏´‡∏£‡∏∑‡∏≠ built-in tools
- **Auto-scaling** - ‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î database resources ‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£

## 16. ‡∏™‡∏£‡∏∏‡∏õ

‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á Database Query ‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡∏≤‡∏®‡∏±‡∏¢‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏£‡∏∞‡∏°‡∏±‡∏î‡∏£‡∏∞‡∏ß‡∏±‡∏á ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÅ‡∏•‡∏∞‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏´‡∏•‡∏±‡∏Å‡∏Ñ‡∏∑‡∏≠:

### üéØ ‡∏Å‡∏•‡∏¢‡∏∏‡∏ó‡∏ò‡πå‡∏´‡∏•‡∏±‡∏Å:
1. **‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏õ‡∏±‡∏ç‡∏´‡∏≤** - ‡πÉ‡∏ä‡πâ EXPLAIN ‡πÅ‡∏•‡∏∞ Monitoring tools
2. **‡∏™‡∏£‡πâ‡∏≤‡∏á Index ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°** - ‡πÑ‡∏°‡πà‡∏°‡∏≤‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ ‡πÑ‡∏°‡πà‡∏ô‡πâ‡∏≠‡∏¢‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ
3. **‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô Query ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û** - ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
4. **‡πÉ‡∏ä‡πâ Caching** - ‡∏•‡∏î‡∏Å‡∏≤‡∏£ Query ‡∏ó‡∏µ‡πà‡∏ã‡πâ‡∏≥‡πÜ
5. **‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á** - ‡∏ß‡∏±‡∏î‡∏ú‡∏•‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á

### üõ†Ô∏è ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á:
- **Common Table Expressions (WITH)** - ‡∏ó‡∏≥‡πÉ‡∏´‡πâ Query ‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û
- **Window Functions** - ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà Self-joins ‡πÅ‡∏•‡∏∞ Subqueries ‡∏ó‡∏µ‡πà‡∏ä‡πâ‡∏≤
- **Temporary Tables** - ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û
- **Bulk Operations** - ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏°‡∏≤‡∏Å‡πÉ‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
- **Query Hints** - ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏° Query Optimizer ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô

### üìä ‡∏Å‡∏≤‡∏£‡∏ß‡∏±‡∏î‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û:
- **Execution Time** - ‡πÄ‡∏ß‡∏•‡∏≤‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
- **Memory Usage** - ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥
- **I/O Operations** - ‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô/‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
- **CPU Usage** - ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Processor
- **Concurrency** - ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô‡∏Ç‡∏≠‡∏á Users

### üîÑ ‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á:
1. **Monitor** - ‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏™‡∏°‡πà‡∏≥‡πÄ‡∏™‡∏°‡∏≠
2. **Analyze** - ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå Bottlenecks ‡πÅ‡∏•‡∏∞‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á
3. **Optimize** - ‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Å‡∏±‡∏ö‡∏õ‡∏±‡∏ç‡∏´‡∏≤
4. **Test** - ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÅ‡∏•‡∏∞‡∏ß‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á
5. **Document** - ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡πÅ‡∏•‡∏∞‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå

‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏°‡∏î‡∏∏‡∏•‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á **‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß** **‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ Memory** **‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ö‡∏≥‡∏£‡∏∏‡∏á‡∏£‡∏±‡∏Å‡∏©‡∏≤** ‡πÅ‡∏•‡∏∞ **‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ Scale** 

> üí° **‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç**: "Premature optimization is the root of all evil" - ‡∏Ñ‡∏ß‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏à‡∏£‡∏¥‡∏á ‡πÅ‡∏•‡∏∞‡∏ß‡∏±‡∏î‡∏ú‡∏•‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
